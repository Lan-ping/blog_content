## 引言
**生成对抗网络 GAN**是两个参与者的游戏，即生成器和判别器，它们广泛应用于合成高质量数据。 对于图像合成，生成器将潜在向量作为输入，并有望生成高质量的合成图像，而鉴别器则有望有效地将它们与真实图像区分开来。

**条件生成对抗网络 CGAN**能够通过将条件嵌入到生成器和判别器的输入中来生成语义图像。CGAN 中的各种条件包括标签、文本和图像，其中标签是最常见的一种。

**灾难性遗忘**：智能体在实践中获得所有训练数据并学习一次是不现实的，我们期望智能体像人类一样获得知识，即在生活中不断学习，快速有效地学习新任务，而不会忘记过去学到的知识。 要实现通用人工智能，需要赋予智能体持续学习的能力。 然而，实验表明，现在深度神经网络在学习新任务（称为灾难性遗忘）时保留先前学习任务中获得的知识仍然具有挑战性。 

GAN 也严重遭受灾难性遗忘的困扰。 例如，在顺序任务训练中，生成器只能为最后一个任务生成令人满意的图像，而忘记了其他先前任务所拥有的能力。

近年来，研究人员为减轻灾难性遗忘做出了一些努力。 例如，**概念辅助反向传播** (CAB) 方法和**正交权重修改** (OWM) 方法已被提出并以一种新的方式来解决这个问题，以进行持续学习。 具体来说，在每一层网络中都构造了一个正交投影矩阵来保存学习到的知识，在学习一个新任务的过程中，神经网络中的梯度通过正交投影矩阵投影到所有先前学习到的特征的正交方向上。更新后的权重不仅可以适应新任务，还可以保留编码旧知识的有效性。 

然而，对于 CGAN，生成器的输入是从除标签条件之外的相同分布中独立采样的随机噪声，它实际上会导致未学习任务的可用内存空间消失。

受 OWM 算法的启发，我们提出了一种新的CGAN，称为**梯度正交投影GAN**（GopGAN），以持续学习的方式生成合成数据，并将其应用于图像的顺序学习任务合成。

本文的主要贡献总结如下：
1. 给出了严格的数学证明，表明在特征空间的正交子空间中更新权重可以保证新任务的学习不会导致忘记旧任务中获得的知识。
2. 通过定义和求解一个优化问题，推导出一个新的投影矩阵的最优解。此外，提出了一种用于持续学习的迭代算法，这样在学习过去的任务中训练样本的特征就不需要为了学习新的任务而存储。
3. 对于GAN，作者发现生成器的噪声输入来自相同的分布，并且为所有类别共享，这使得计算的投影矩阵容易接近零矩阵，很少有内存空间可用于新任务。为了解决这个问题，作者提出了一个新的任务相关的潜在向量，使每个任务具有不同的潜在向量，从而为新任务获得足够的内存空间。

## 相关工作
近年来，生成对抗网络（GAN）在图像生成方面已经显示出其有效性。 然而，如果没有监督条件，生成图像的类别是不可预测的。 Mirza 和 Osindero 提出了一种条件生成对抗网络（CGAN）来生成带有条件的语义图像。我们采用带有标签条件的 CGAN 作为本文的基本网络架构。

持续学习旨在赋予智能体学习序列任务的能力，而不会忘记在先前任务中获得的知识。近年来已经见证了一些努力，其中大部分集中在模型学习中权重梯度的修改。Kirkpatrick 等人提出了一种称为弹性权重合并 (EWC) 的方法，该方法在新任务和旧任务之间引入了权重约束。然而，在序列任务训练中，带有 EWC 的网络会为每个学习任务保留一个 Fisher 矩阵，Fisher 正则化器的积累会过度约束网络参数，导致新任务的学习障碍。施瓦茨等人。Schwarz 等人提出了一种改进的 EWC，称为 Online EWC，可扩展到大量任务。与 Online EWC 类似，Chaudhry 等人提出了 EWC++，在更新 Fisher 矩阵方面与 Online EWC 略有不同。开创性的工作 CAB 和 OWM 是反向传播算法的变体，并已成功应用于分类任务，但我们发现没有将这两种方法应用于 GAN 的工作。 **CAB 和 OWM 是两种类似的解决灾难性遗忘的方法，通过沿学习任务特征空间的正交方向更新网络权重。** CAB 和 OWM 的区别在于投影矩阵的设计。 CAB基于 Conceptor 构造投影矩阵，OWM基于递归最小二乘（RLS）算法。与 CAB 和 OWM 不同，本文作者重新定义了正交投影矩阵的形式并将其应用于 GAN。

GAN 在持续学习中也会遭受灾难性遗忘。Seff 等人将 EWC 应用于 GAN，这在一定程度上提高了生成图像的质量。Wu 等人提出了基于**记忆重放机制**的记忆重放 GAN（MeRGAN），以减轻对先前类别的遗忘。在 MeRGAN 中，提出了两种方法，即重放联合训练 (MeRGAN-JTR) 和重放对齐 (MeRGAN-RA)。但是，它们都需要大量的内存空间来重播旧任务，这将占用大量的网络训练空间和时间。基于 MeRGANs，Rios 等人提出了一种**累积闭环记忆重放** GAN（CloGAN），它通过设置每个旧任务的集群来减少记忆空间。与 MeRGAN 相比，CloGAN 节省了大量内存空间，但略微降低了生成图像的质量。++本质上，MeRGANs 和 CloGAN 是对旧任务进行再训练的方法，不保留所学知识，这是与本文方法的最大区别。++ 本文所提出的 GopGAN 可以保留学习到的知识，并且不需要重播旧任务。Zhai 等人提出 LifelongGAN 使用**知识蒸馏**的方法将从之前的网络中学到的知识转移到新的网络中。++虽然知识蒸馏可以使新网络在一定程度上继承前一个网络所学的知识，但会破坏当前网络对前一个任务的响应。根据持续学习的约束规则，该方法不能利用之前的任务数据进行知识蒸馏，导致网络在学习新任务后对之前的任务数据的响应出现偏差。++ Ye 等人提出了一个终生的 VAEGAN 来诱导强大的**生成重放网络**来学习有意义的潜在表示，从而有利于表示学习。他们还将生成重放网络应用于无监督、半监督和监督学习，并取得了很好的效果。<u>本文作者给出了严格的理论证明，证明作者的方法可以保持新网络对学习任务的输入响应不变，从而消除了灾难性遗忘问题，这也被大量实验证明。</u>

## 梯度正交投影生成对抗网络 GopGAN
### GAN 的持续学习设置
GopGAN 使用 CGAN 作为基础网络架构来生成语义图像。CGAN 由生成器 $G$ 和鉴别器 $D$ 组成。生成器 $G$ 以潜在向量 $z$ 和标签条件 $c$ 作为输入来生成假图像 $\widetilde I $，即 $\widetilde I = G(z|c)$，其中 $z$ 是从随机高斯采样 噪声分布，$c$ 是持续学习中每个特定任务的固定 one-hot 向量。 判别器 $D$ 接收条件向量 $c$ 和由 $G$ 生成的真实训练图像 $I$ 或假图像 $\widetilde I $ 并输出一个概率标量来表明输入图像是真还是假。 CGAN网络的优化目标函数可以表示为:

$$
\underset{G}{\min}\;\underset{D}{\max}\;V(D,G)=\mathbb{E}_{I\sim p_{data}}[\log D(I|c)]+\mathbb{E}_{z\sim p_{z}}[\log (1-D(G(z|c)))]
$$

其中，$p_{data}$和$p_z$分别表示真实数据和潜在向量的分布。

当我们应用 GAN 生成多类别假数据时，可以将其建模为序列任务或持续学习的学习问题。在持续学习中，学习顺序可以是任意的。为简化起见，假设我们有$M$个学习任务，它们用$T_i$表示，$i = 1, 2, ... , M$, 其中$i$正好对应于学习顺序。每个任务对应一个类别，因此其训练数据$D_i$具有相同的标签$c_i$。 只有当任务$T_i$完全完成后，任务$T_{i+1}$才能开始训练，同时我们期望学习任务中的训练数据$\cup_{k=1}^{i}$对任务$T_{i+1}$是不可用的。

